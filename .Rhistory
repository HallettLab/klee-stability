geom_abline(aes(intercept = 0, slope = 45)) + ## boundary of predicted coexistence or competitive exclusion
theme(text = element_text(size = 14))
setwd("~/Research/California Experiment")
setwd("~/Research/California Experiment")
s14 <- read.csv("scott14-control-meancover-byyear.csv")
View(s14)
library(tidyverse)
s14_2010 <- s14 %>%
filter(year == "y2010")
ggplot(s14_2010, aes(x=species, y=meancover)) %>%
geom_point()
ggplot(s14_2010, aes(x=species, y=meancover)) +
geom_point()
ggplot(s14_2010, aes(x=species, y=meancover)) +
geom_point() +
facet_wrap(~grazing_level)
s14_2010 <- s14 %>%
filter(year == "y2010", meancover > 0)
ggplot(s14_2010, aes(x=species, y=meancover)) +
geom_point() +
facet_wrap(~grazing_level)
s14_2010 <- s14 %>%
filter(year == "y2010", meancover > 0.5)
ggplot(s14_2010, aes(x=species, y=meancover)) +
geom_point() +
facet_wrap(~grazing_level)
s14_2010 <- s14 %>%
filter(year == "y2010", meancover > 0.5, grazing_level == "G0")
ggplot(s14_2010, aes(x=species, y=meancover)) +
geom_point() +
facet_wrap(~grazing_level)
s14g0 <- s14 %>%
filter(meancover > 0.5, grazing_level == "G0")
ggplot(s14g0, aes(x=species, y=meancover)) +
geom_point() +
facet_wrap(~year)
s <- s14 %>%
filter(meancover > 2.5)
ggplot(s, aes(x= meancover, y= species)) +
geom_point() +
facet_wrap(~year)
ggplot(s, aes(x= meancover, y= species, color = grazing_treatment)) +
geom_point() +
facet_wrap(~year)
ggplot(s, aes(x= meancover, y= species, color = grazing_level)) +
geom_point() +
facet_wrap(~year)
s <- s14 %>%
filter(meancover > 1.5)
ggplot(s, aes(x= meancover, y= species, color = grazing_level)) +
geom_point() +
facet_wrap(~year)
s <- s14 %>%
filter(meancover > 0.5)
ggplot(s, aes(x= meancover, y= species, color = grazing_level)) +
geom_point() +
facet_wrap(~year)
ppt <- read.csv("KLEE_monthly_precipitation_03‑13.csv")
setwd("~/Repositories/klee-stability")
ppt <- read.csv("KLEE_monthly_precipitation_03‑13.csv")
setwd("~/Repositories/klee-stability")
setwd("~/Repositories/klee-stability")
ppt <- read.csv("KLEE_monthly_precipitation_03‑13.csv")
ppt <- read.csv("KLEE_monthly_precipitation_03_13.csv")
View(ppt)
library(tidyverse)
colnames(ppt)
colnames(ppt) <- c("Month", "North", "Central", "South", "Average", "std.error")
ggplot(ppt, aes(x=Month, y=Average)) +
geom_line()
ggplot(ppt, aes(x=Month, y=Average)) +
geom_point()
ppt2 <- ppt %>%
str_split(Month, " ")
ppt2 <- ppt %>%
str_split(ppt$Month, " ")
str_split(ppt$Month, " ")
ppt$Date <- str_split(ppt$Month, " ")
View(ppt)
ppt <- read.csv("KLEE_monthly_precipitation_03_13.csv")
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ")
ppt2 <- ppt %>%
separate("Month", into = c("Month", "Year"), sep = " ")
colnames(ppt) <- c("Month", "North", "Central", "South", "Average", "std.error")
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ")
View(ppt2)
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15)
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_"))
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_")) %>%
mutate(Date_temp2 = paste(Date_temp, Day, sep = "_"))
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_")) %>%
mutate(Date_temp2 = paste(Date_temp, Day, sep = "_")) %>%
mutate(Date_final = ymd(Date_temp2)) %>% #change dates into recognized format
ggplot(ppt, aes(x=Month, y=Average)) +
geom_point()
library(lubridate)
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_")) %>%
mutate(Date_temp2 = paste(Date_temp, Day, sep = "_")) %>%
mutate(Date_final = ymd(Date_temp2)) %>% #change dates into recognized format
ggplot(ppt, aes(x=Month, y=Average)) +
geom_point()
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_")) %>%
mutate(Date_temp2 = paste(Date_temp, Day, sep = "_")) %>%
mutate(Date_final = ymd(Date_temp2)) #change dates into recognized format
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_")) %>%
mutate(Date_temp2 = paste(Date_temp, Day, sep = "_")) %>%
mutate(Date_final = ymd(Date_temp2)) %>% #change dates into recognized format
select(-(Month, Day, Year, Date_temp:Date_temp2))
ppt2 <- ppt %>%
separate(Month, into = c("Month", "Year"), sep = " ") %>%
mutate(Day = 15) %>%
mutate(Date_temp = paste(Year, Month, sep = "_")) %>%
mutate(Date_temp2 = paste(Date_temp, Day, sep = "_")) %>%
mutate(Date_final = ymd(Date_temp2)) %>% #change dates into recognized format
select(-Month, -Day, -Year, -Date_temp, -Date_temp2)
ggplot(ppt, aes(x=Date_final, y=Average)) +
geom_point()
ggplot(ppt2, aes(x=Date_final, y=Average)) +
geom_point()
ggplot(ppt2, aes(x=Date_final, y=Average)) +
geom_line()
ggplot(ppt2, aes(x=Date_final, y=Average)) +
geom_line() +
xlab("Date") + ylab("Average Monthly Precipitation (mm)")
ggplot(ppt2, aes(x=Date_final, y=Average)) +
geom_line() +
xlab("Date") + ylab("Average Monthly Precipitation (mm)") +
theme_bw()
source("precipitation_data_cleaning.R")
## Load Packages, Read in Data ##
## set working directory
setwd("~/Repositories/klee-stability")
## Load packages
library(tidyverse)
library(lubridate)
library(codyn)
library(tsvr)
library(RColorBrewer)
library(forcats)
library(knitr)
library(bookdown)
library(ggpubr)
library(data.table)
## source cleaned data
source("klee_data_cleaning_current.R")
source("precipitation_data_cleaning.R")
## Load Packages, Read in Data ##
## set working directory
setwd("~/Repositories/klee-stability")
## Load packages
library(tidyverse)
library(lubridate)
library(codyn)
library(tsvr)
library(RColorBrewer)
library(forcats)
library(knitr)
library(bookdown)
library(ggpubr)
library(data.table)
## source cleaned data
source("klee_data_cleaning_current.R")
source("precipitation_data_cleaning.R")
## Calculate Community Stability ##
## calc community stability metric for each plot
commstab <- community_stability(klee_long,
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
## join with treatment info & calculate CV
stability <- left_join(commstab, treats, by = "Unique_ID") %>% #join community stability with treatment info
mutate(CV = 1/stability) #calculate the CV by taking the inverse of stability
rm(commstab)
## create a dataframe with mean & standard error of stability & CV by treatment
mean_stability <- stability %>%
group_by(TREATMENT) %>%
summarize(mean_st = mean(stability), SEst = calcSE(stability), mean_cv = mean(CV), SECV = calcSE(CV))
## reorder treatments to match grazing pressure.
mean_stability$TREATMENT <- as.factor(mean_stability$TREATMENT) #change treatment to factor
mean_stability$TREATMENT <- factor(mean_stability$TREATMENT, levels = c("0", "W",  "MW",  "C", "MWC", "WC"))
## Calculate Variance
## calculate the variance of each plot over time
varian <- klee_long %>%
group_by(TREATMENT, Unique_ID) %>%
summarise(variance = var(Pin_Hits)) %>%
group_by(TREATMENT) %>%
summarise(meanvar = mean(variance), SEvar = calcSE(variance)) ## calculate mean and standard error
variance <- klee_long %>%
group_by(TREATMENT, Unique_ID) %>%
summarise(variance = var(Pin_Hits))
pinhits <- meantotcov %>%
group_by(TREATMENT, Unique_ID) %>%
summarize(pinhits = mean(Mean_TotCov))
meanvar18 <- left_join(variance, pinhits, by = c("TREATMENT", "Unique_ID"))
meanvar6 <- meanvar18 %>%
group_by(TREATMENT) %>%
summarize(meanvar = mean(variance),
SEvar = calcSE(variance),
meanbio = mean(pinhits),
SEbio = mean(pinhits))
## reorder treatments to match grazing pressure.
varian$TREATMENT <- as.factor(varian$TREATMENT) #change treatment to factor
varian$TREATMENT <- factor(varian$TREATMENT, levels = c("0", "W",  "MW",  "C", "MWC", "WC"))
## How does the change in sampling frequency affect stability?
## Look at the bi-annual samples & compare stability using all and June only
sort(unique(klee_long$Date_final)) #sort unique sampling dates
## looks like bi-annual sampling stops after 2010
## create the bi-annual data frame (before 2011)
biannual <- klee_long %>%
filter(Date_numeric < 20110601)
annual1 <- klee_long[klee_long$Date_final %like% "-06", ]        # Extract matching rows with %like%
annual2 <- klee_long[klee_long$Date_final %like% "-05", ]
annual_all <- rbind(annual1, annual2)
annual <- rbind(annual1, annual2) %>%
filter(Date_numeric < 20110601)
sort(unique(annual$Date_final))
biannual_stab <- community_stability(biannual,
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
annual_stab <- community_stability(annual,
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
colnames(biannual_stab) <- c("Unique_ID", "biannual")
colnames(annual_stab) <- c("Unique_ID", "annual")
stabfreq_test <- left_join(biannual_stab, annual_stab, by="Unique_ID")
stabfreq_test <- left_join(stabfreq_test, treats) %>%
pivot_longer(2:3, names_to = "frequency", values_to = "stability")
meanfreqstab <- stabfreq_test %>%
group_by(TREATMENT, frequency) %>%
summarize(mean = mean(stability), SE = calcSE(stability))
ggplot(meanfreqstab, aes(x=TREATMENT, y=mean, color=frequency)) +
geom_point() +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE), width=0.25) +
xlab("Treatment") + ylab("Mean Stability") +
theme_bw()
rm(list = c("biannual", "annual1", "annual2", "annual", "annual_stab", "biannual_stab", "stabfreq_test"))
## Calculate Stability over a Moving Window ##
## create function
movingwindow_func <- function(input_data, timestep, ...) { ## function inputs = data frame and number of time steps
n_samples <- length(unique(input_data$Date_final)) ## number of sampling points
n_windows <- n_samples - timestep + 1 ## how many windows to iterate over
movingwindow <- data.frame(matrix(ncol=3,nrow=(n_windows*length(unique(input_data$Unique_ID))))) ## create empty dataframe to contain output ## dimensions = # cols (3) x (uniqueID x timesteps)
colnames(movingwindow) <- c("Unique_ID", "stability", "timestep")
sample_points <- sort(unique(input_data$Date_numeric)) ## create ordered list of sample points
n_plots <- length(unique(input_data$Unique_ID)) ## number of unique plots
for (i in 1:n_windows){
temp_samplepts <- sample_points[i:(i+timestep-1)] ## create a vector of sample points for each iteration
temp <- input_data %>%
filter(Date_numeric %in% temp_samplepts) ## filter the correct sample points from input data to run through the community stability function
temp_commstab <- community_stability(temp,  ## run the community stability function from codyn
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
temp_commstab$timestep <- i ## create a column for timestep in the temporary data frame
movingwindow[((i-1)*n_plots + 1):(i*n_plots),] <- temp_commstab ## add stability calculations for one iteration to the moving window data frame
## ((i-1)*n_plots + 1):(i*n_plots) -> where to put each iteration of the loop
}
return(movingwindow) ## retrieve data frame at the end
}
## Use moving window function to calculate stability with ONLY June sampling points
annual_stab3 <- movingwindow_func(input_data = annual_all, timestep = 3)
annual_stab5 <- movingwindow_func(input_data = annual_all, timestep = 5)
annual_stab7 <- movingwindow_func(input_data = annual_all, timestep = 7)
annual_stab10 <- movingwindow_func(input_data = annual_all, timestep = 10)
## Load Packages, Read in Data ##
## set working directory
setwd("~/Repositories/klee-stability")
## Load packages
library(tidyverse)
library(lubridate)
library(codyn)
library(tsvr)
library(RColorBrewer)
library(forcats)
library(knitr)
library(bookdown)
library(ggpubr)
library(data.table)
## source cleaned data
source("klee_data_cleaning_current.R")
source("precipitation_data_cleaning.R")
## Load Packages, Read in Data ##
## set working directory
setwd("~/Repositories/klee-stability")
## Load packages
library(tidyverse)
library(lubridate)
library(codyn)
library(tsvr)
library(RColorBrewer)
library(forcats)
library(knitr)
library(bookdown)
library(ggpubr)
library(data.table)
## source cleaned data
source("klee_data_cleaning_current.R")
source("precipitation_data_cleaning.R")
## Calculate Community Stability ##
## calc community stability metric for each plot
commstab <- community_stability(klee_long,
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
## join with treatment info & calculate CV
stability <- left_join(commstab, treats, by = "Unique_ID") %>% #join community stability with treatment info
mutate(CV = 1/stability) #calculate the CV by taking the inverse of stability
rm(commstab)
## create a dataframe with mean & standard error of stability & CV by treatment
mean_stability <- stability %>%
group_by(TREATMENT) %>%
summarize(mean_st = mean(stability), SEst = calcSE(stability), mean_cv = mean(CV), SECV = calcSE(CV))
## reorder treatments to match grazing pressure.
mean_stability$TREATMENT <- as.factor(mean_stability$TREATMENT) #change treatment to factor
mean_stability$TREATMENT <- factor(mean_stability$TREATMENT, levels = c("0", "W",  "MW",  "C", "MWC", "WC"))
## Calculate Variance
## calculate the variance of each plot over time
varian <- klee_long %>%
group_by(TREATMENT, Unique_ID) %>%
summarise(variance = var(Pin_Hits)) %>%
group_by(TREATMENT) %>%
summarise(meanvar = mean(variance), SEvar = calcSE(variance)) ## calculate mean and standard error
variance <- klee_long %>%
group_by(TREATMENT, Unique_ID) %>%
summarise(variance = var(Pin_Hits))
pinhits <- meantotcov %>%
group_by(TREATMENT, Unique_ID) %>%
summarize(pinhits = mean(Mean_TotCov))
meanvar18 <- left_join(variance, pinhits, by = c("TREATMENT", "Unique_ID"))
meanvar6 <- meanvar18 %>%
group_by(TREATMENT) %>%
summarize(meanvar = mean(variance),
SEvar = calcSE(variance),
meanbio = mean(pinhits),
SEbio = mean(pinhits))
## reorder treatments to match grazing pressure.
varian$TREATMENT <- as.factor(varian$TREATMENT) #change treatment to factor
varian$TREATMENT <- factor(varian$TREATMENT, levels = c("0", "W",  "MW",  "C", "MWC", "WC"))
## How does the change in sampling frequency affect stability?
## Look at the bi-annual samples & compare stability using all and June only
sort(unique(klee_long$Date_final)) #sort unique sampling dates
## looks like bi-annual sampling stops after 2010
## create the bi-annual data frame (before 2011)
biannual <- klee_long %>%
filter(Date_numeric < 20110601)
annual1 <- klee_long[klee_long$Date_final %like% "-06", ]        # Extract matching rows with %like%
annual2 <- klee_long[klee_long$Date_final %like% "-05", ]
annual_all <- rbind(annual1, annual2)
annual <- rbind(annual1, annual2) %>%
filter(Date_numeric < 20110601)
sort(unique(annual$Date_final))
biannual_stab <- community_stability(biannual,
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
annual_stab <- community_stability(annual,
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
colnames(biannual_stab) <- c("Unique_ID", "biannual")
colnames(annual_stab) <- c("Unique_ID", "annual")
stabfreq_test <- left_join(biannual_stab, annual_stab, by="Unique_ID")
stabfreq_test <- left_join(stabfreq_test, treats) %>%
pivot_longer(2:3, names_to = "frequency", values_to = "stability")
meanfreqstab <- stabfreq_test %>%
group_by(TREATMENT, frequency) %>%
summarize(mean = mean(stability), SE = calcSE(stability))
ggplot(meanfreqstab, aes(x=TREATMENT, y=mean, color=frequency)) +
geom_point() +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE), width=0.25) +
xlab("Treatment") + ylab("Mean Stability") +
theme_bw()
rm(list = c("biannual", "annual1", "annual2", "annual", "annual_stab", "biannual_stab", "stabfreq_test"))
## Calculate Stability over a Moving Window ##
## create function
movingwindow_func <- function(input_data, timestep, ...) { ## function inputs = data frame and number of time steps
n_samples <- length(unique(input_data$Date_final)) ## number of sampling points
n_windows <- n_samples - timestep + 1 ## how many windows to iterate over
movingwindow <- data.frame(matrix(ncol=3,nrow=(n_windows*length(unique(input_data$Unique_ID))))) ## create empty dataframe to contain output ## dimensions = # cols (3) x (uniqueID x timesteps)
colnames(movingwindow) <- c("Unique_ID", "stability", "timestep")
sample_points <- sort(unique(input_data$Date_numeric)) ## create ordered list of sample points
n_plots <- length(unique(input_data$Unique_ID)) ## number of unique plots
for (i in 1:n_windows){
temp_samplepts <- sample_points[i:(i+timestep-1)] ## create a vector of sample points for each iteration
temp <- input_data %>%
filter(Date_numeric %in% temp_samplepts) ## filter the correct sample points from input data to run through the community stability function
temp_commstab <- community_stability(temp,  ## run the community stability function from codyn
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
temp_commstab$timestep <- i ## create a column for timestep in the temporary data frame
movingwindow[((i-1)*n_plots + 1):(i*n_plots),] <- temp_commstab ## add stability calculations for one iteration to the moving window data frame
## ((i-1)*n_plots + 1):(i*n_plots) -> where to put each iteration of the loop
}
return(movingwindow) ## retrieve data frame at the end
}
## Use moving window function to calculate stability with ONLY June sampling points
annual_stab3 <- movingwindow_func(input_data = annual_all, timestep = 3)
annual_stab5 <- movingwindow_func(input_data = annual_all, timestep = 5)
annual_stab7 <- movingwindow_func(input_data = annual_all, timestep = 7)
annual_stab10 <- movingwindow_func(input_data = annual_all, timestep = 10)
## Calculate Synchrony Metrics ##
## Calculate Loreau synchrony metric
loreau_synchrony <- synchrony(
klee_long,
time.var = "Date_numeric",
species.var = "SPECIES",
abundance.var = "Pin_Hits",
metric = "Loreau",
replicate.var = "Unique_ID"
)
colnames(loreau_synchrony) <- c("Unique_ID", "loreau_synchrony") #rename columns
## Calculate Gross synchrony metric
gross_synchrony <- synchrony(
klee_long,
time.var = "Date_numeric",
species.var = "SPECIES",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID",
metric="Gross")
colnames(gross_synchrony) <- c("Unique_ID", "gross_synchrony") #rename columns
## join two synchrony metrics into one data frame
synchrony <- left_join(loreau_synchrony, gross_synchrony, by = "Unique_ID")
## join with treatment data
synchrony_tx <- inner_join(synchrony, treats, by = "Unique_ID")
synchrony_stability <- left_join(synchrony, stability, by = "Unique_ID")
rm(loreau_synchrony)
rm(gross_synchrony)
## calculate mean & SE of metrics to get ready for graphing
mean_synchrony <- left_join(synchrony, treats, by = "Unique_ID") %>%
pivot_longer(cols = loreau_synchrony:gross_synchrony, names_to = "Metric_Name", values_to = "Synchrony") %>% #pivot to long format
group_by(TREATMENT, Metric_Name) %>%
summarise(mean_value = mean(Synchrony), SE_value = calcSE(Synchrony))
## reorder treatments to match grazing pressure.
mean_synchrony$TREATMENT <- as.factor(mean_synchrony$TREATMENT) #change treatment to factor
mean_synchrony$TREATMENT <- factor(mean_synchrony$TREATMENT, levels = c("0", "W",  "MW",  "C", "MWC", "WC"))
## join synchrony & stability data frames to get ready for graphing
syn_stab <- inner_join(mean_synchrony, mean_stability, by = "TREATMENT")
## Synchrony over a Moving Window ##
## create function
synchronymw_func <- function(input_data, timestep, ...) { ## function inputs = data frame and number of time steps
n_samples <- length(unique(input_data$Date_final)) ## number of sampling points
n_windows <- n_samples - timestep + 1 ## how many windows to iterate over
mw_synchrony <- data.frame(matrix(ncol=4,nrow=(n_windows*length(unique(input_data$Unique_ID))))) ## create empty dataframe to contain output ## dimensions = # cols (3) x (uniqueID x timesteps)
colnames(mw_synchrony) <- c("Unique_ID", "loreau_synchrony", "timestep", "gross_synchrony")
sample_points <- sort(unique(input_data$Date_numeric)) ## create ordered list of sample points
n_plots <- length(unique(input_data$Unique_ID)) ## number of unique plots
for (k in 1:n_windows){
temp_samplepts <- sample_points[k:(k+timestep-1)] ## create a vector of sample points for each iteration
temp <- input_data %>%
filter(Date_numeric %in% temp_samplepts) ## filter the correct sample points from input data to run through the community stability function
## Calculate Loreau synchrony metric
temp_lsyn <- synchrony(
temp,
time.var = "Date_numeric",
species.var = "SPECIES",
abundance.var = "Pin_Hits",
metric = "Loreau",
replicate.var = "Unique_ID"
)
colnames(temp_lsyn) <- c("Unique_ID", "loreau_synchrony") #rename columns
temp_lsyn$timestep <- k ## create a column for timestep in the temporary data frame
## Calculate Gross synchrony metric
temp_gsyn <- synchrony(
temp,
time.var = "Date_numeric",
species.var = "SPECIES",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID",
metric="Gross")
colnames(temp_gsyn) <- c("Unique_ID", "gross_synchrony") #rename columns
temp_gsyn$timestep <- k ## create a column for timestep in the temporary data frame
## join synchrony dataframes together
tempsynch <- left_join(temp_lsyn, temp_gsyn, by= c("Unique_ID", "timestep"))
mw_synchrony[((k-1)*n_plots + 1):(k*n_plots),] <- tempsynch ## add synchrony calculations for one iteration to the moving window data frame
## ((i-1)*n_plots + 1):(i*n_plots) -> where to put each iteration of the loop
}
return(mw_synchrony) ## retrieve data frame at the end
}
#synchrony3 <- synchronymw_func(input_data = annual_all, timestep = 3)
#this returned the message "One or more species has non-varying abundance within a subplot and has been omitted" many times. Probably too short of a timescale to run the synchrony functions over
synchrony4 <- synchronymw_func(input_data = annual_all, timestep = 4)
#got same error message, but only once
synchrony5 <- synchronymw_func(input_data= annual_all, timestep = 5)
#this only returned 11 timesteps. Not sure what happened?
#this is because it has only the June sampling points.
synchrony7 <- synchronymw_func(input_data = annual_all, timestep = 7)
synchrony10 <- synchronymw_func(input_data = annual_all, timestep = 10)
