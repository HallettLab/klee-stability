# Log response variables to mirror original analysis of Byrnes et al 2011
kelp$kelp = log(kelp$kelp+1)
kelp$prev.kelp = log(kelp$prev.kelp + 1)
kelp[, 18:23] = log(kelp[, 18:23] + 1)
vars = c("SITE", "TRANSECT", "YEAR", "max_Max.OV", "prev.kelp", "habitat", "spring_canopy_150", "kelp",
"algae_richness", "sessile_invert_richness", "mobile_richness", "richness", "consumer_richness", "linkdensity")
kelp = kelp[, vars]
kelp = na.omit(kelp)
# Create interaction term
kelp$wave_kelp_int = kelp$max_Max.OV * kelp$prev.kelp
kelp_model = '
spring_canopy_150 ~ max_Max.OV + prev.kelp + wave_kelp_int + habitat
kelp ~ max_Max.OV + prev.kelp  + habitat + spring_canopy_150
richness ~ kelp   + prev.kelp  + habitat + spring_canopy_150
linkdensity ~ richness  + kelp  + prev.kelp  + habitat + spring_canopy_150
'
# Fit vcov SEM
kelp_model.sem = sem(kelp_model, kelp, estimator = "MLM")
# Summary output with standardized coefficients
summary(kelp_model.sem, standardize = TRUE)
# Get R2 for models
inspect(kelp_model.sem, "rsquare")
## Create Stability over a Moving Window Function
movingwindow_func <- function(input_data, timestep, ...) { ## function inputs = data frame and number of time steps
n_samples <- length(unique(input_data$Date_final)) ## number of sampling points
n_windows <- n_samples - timestep + 1 ## how many windows to iterate over
movingwindow <- data.frame(matrix(ncol=3,nrow=(n_windows*length(unique(input_data$Unique_ID))))) ## create empty dataframe to contain output ## dimensions = # cols (3) x (uniqueID x timesteps)
colnames(movingwindow) <- c("Unique_ID", "stability", "timestep")
sample_points <- sort(unique(input_data$Date_numeric)) ## create ordered list of sample points
n_plots <- length(unique(input_data$Unique_ID)) ## number of unique plots
for (i in 1:n_windows){
temp_samplepts <- sample_points[i:(i+timestep-1)] ## create a vector of sample points for each iteration
temp <- input_data %>%
filter(Date_numeric %in% temp_samplepts) ## filter the correct sample points from input data to run through the community stability function
temp_commstab <- community_stability(temp,  ## run the community stability function from codyn
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
temp_commstab$timestep <- i ## create a column for timestep in the temporary data frame
movingwindow[((i-1)*n_plots + 1):(i*n_plots),] <- temp_commstab ## add stability calculations for one iteration to the moving window data frame
## ((i-1)*n_plots + 1):(i*n_plots) -> where to put each iteration of the loop
}
return(movingwindow) ## retrieve data frame at the end
}
mw_size <- c(5:21) ## set range of sizes for the moving window
## create dataframe to contain output
mwstability <- data.frame(Unique_ID = NA, stability = NA, timestep = NA, window_size = NA)
## run the moving window function over the whole range of window sizes
for(i in 1:length(mw_size)){
tmws <- movingwindow_func(input_data = klee_annual, timestep = mw_size[i]) %>%
mutate(window_size = mw_size[i])
mwstability <- rbind(mwstability, tmws)
}
mwstability <- mwstability[-1,]
## Load packages
library(tidyverse)
setwd("~/Repositories/klee-stability")
## Load packages
library(tidyverse)
## source cleaned data
source("klee_allyears_cleaning.R")
source("precipitation_data_cleaning.R")
mw_size <- c(5:21) ## set range of sizes for the moving window
## create dataframe to contain output
mwstability <- data.frame(Unique_ID = NA, stability = NA, timestep = NA, window_size = NA)
## run the moving window function over the whole range of window sizes
for(i in 1:length(mw_size)){
tmws <- movingwindow_func(input_data = klee_annual, timestep = mw_size[i]) %>%
mutate(window_size = mw_size[i])
mwstability <- rbind(mwstability, tmws)
}
## source cleaned data
source("klee_allyears_cleaning.R")
## Create Stability over a Moving Window Function
movingwindow_func <- function(input_data, timestep, ...) { ## function inputs = data frame and number of time steps
n_samples <- length(unique(input_data$Date_final)) ## number of sampling points
n_windows <- n_samples - timestep + 1 ## how many windows to iterate over
movingwindow <- data.frame(matrix(ncol=3,nrow=(n_windows*length(unique(input_data$Unique_ID))))) ## create empty dataframe to contain output ## dimensions = # cols (3) x (uniqueID x timesteps)
colnames(movingwindow) <- c("Unique_ID", "stability", "timestep")
sample_points <- sort(unique(input_data$Date_numeric)) ## create ordered list of sample points
n_plots <- length(unique(input_data$Unique_ID)) ## number of unique plots
for (i in 1:n_windows){
temp_samplepts <- sample_points[i:(i+timestep-1)] ## create a vector of sample points for each iteration
temp <- input_data %>%
filter(Date_numeric %in% temp_samplepts) ## filter the correct sample points from input data to run through the community stability function
temp_commstab <- community_stability(temp,  ## run the community stability function from codyn
time.var = "Date_numeric",
abundance.var = "Pin_Hits",
replicate.var = "Unique_ID")
temp_commstab$timestep <- i ## create a column for timestep in the temporary data frame
movingwindow[((i-1)*n_plots + 1):(i*n_plots),] <- temp_commstab ## add stability calculations for one iteration to the moving window data frame
## ((i-1)*n_plots + 1):(i*n_plots) -> where to put each iteration of the loop
}
return(movingwindow) ## retrieve data frame at the end
}
## Apply Stability Moving Window Function
mw_size <- c(5:21) ## set range of sizes for the moving window
## create dataframe to contain output
mwstability <- data.frame(Unique_ID = NA, stability = NA, timestep = NA, window_size = NA)
## run the moving window function over the whole range of window sizes
for(i in 1:length(mw_size)){
tmws <- movingwindow_func(input_data = klee_annual, timestep = mw_size[i]) %>%
mutate(window_size = mw_size[i])
mwstability <- rbind(mwstability, tmws)
}
library(codyn)
## run the moving window function over the whole range of window sizes
for(i in 1:length(mw_size)){
tmws <- movingwindow_func(input_data = klee_annual, timestep = mw_size[i]) %>%
mutate(window_size = mw_size[i])
mwstability <- rbind(mwstability, tmws)
}
mwstability <- mwstability[-1,] ## remove the first row of NA values
## join with treatment information
stab_mw_tx <- left_join(mwstability, treats, by="Unique_ID")
## calculate the mean stability for each treatment by window size
mean_mwstab <- left_join(mwstability, treats, by="Unique_ID") %>%
group_by(TREATMENT, window_size) %>%
summarise(mean_stab = mean(stability), SE_stab = calcSE(stability))
source("current_scripts/movingwindow_calcs.R")
View(tmws)
source("current_scripts/movingwindow_calcs.R")
rm(list = c("jk", "jk2", "nondom", "tmws", "totcov", "avg_biomass", "big5annual",
"klee_annual", "klee_long", "mean_mwstab", "mw_classicVR", "mwstability",
"stab_mw_tx"))
library(tsvr)
source("current_scripts/movingwindow_calcs.R")
rm(list = c("jk", "jk2", "nondom", "tmws", "totcov", "avg_biomass", "big5annual",
"klee_annual", "klee_long", "mean_mwstab", "mw_classicVR", "mwstability",
"stab_mw_tx", "cVR_mw_tx", "cvrmw10", "cvrmw5"))
rm(list = c("jk", "jk2", "nondom", "tmws", "totcov", "avg_biomass", "big5annual",
"klee_annual", "klee_long", "mean_mwstab", "mw_classicVR", "mwstability",
"stab_mw_tx", "cVR_mw_tx", "cvrmw10", "cvrmw5", "mean_mwcVR",
"mean_mwpopst"))
rm(list = c("jk", "jk2", "nondom", "tmws", "totcov", "avg_biomass", "big5annual",
"klee_annual", "klee_long", "mean_mwstab", "mw_classicVR", "mwstability",
"stab_mw_tx", "cVR_mw_tx", "cvrmw10", "cvrmw5", "mean_mwcVR",
"mean_mwpopst", "tmwr", "tmwcVR", "stabmw5", "stabmw10", "spstmw5"))
rm(list = c("jk", "jk2", "nondom", "tmws", "totcov", "avg_biomass", "big5annual",
"klee_annual", "klee_long", "mean_mwstab", "mw_classicVR", "mwstability",
"stab_mw_tx", "cVR_mw_tx", "cvrmw10", "cvrmw5", "mean_mwcVR",
"mean_mwpopst", "tmwr", "tmwcVR", "stabmw5", "stabmw10", "spstmw5",
"mean_mwrich", "mwrichness", "mwspstab", "popst_mw_tx", "psmw"))
rm(list = c("jk", "jk2", "nondom", "tmws", "totcov", "avg_biomass", "big5annual",
"klee_annual", "klee_long", "mean_mwstab", "mw_classicVR", "mwstability",
"stab_mw_tx", "cVR_mw_tx", "cvrmw10", "cvrmw5", "mean_mwcVR",
"mean_mwpopst", "tmwr", "tmwcVR", "stabmw5", "stabmw10", "spstmw5",
"mean_mwrich", "mwrichness", "mwspstab", "popst_mw_tx", "psmw",
"rich_mw_tx", "richmw10", "richmw5", "spstmw10"))
source("current_scripts/movingwindow_calcs.R")
source("current_scripts/drought_score_calcs.R")
source("current_scripts/drought_score_calcs.R")
source("current_scripts/drought_score_calcs.R")
source("current_scripts/drought_score_calcs.R")
source("current_scripts/full_timeseries_calcs.R")
source("current_scripts/full_timeseries_calcs.R")
source("current_scripts/full_timeseries_calcs.R")
rm(list = c("avg_biomass", "b5meantsVR", "b5siteout", "b5tsVR", "big5annual",
"big5meanannrich"))
rm(list = c("avg_biomass", "b5meantsVR", "b5siteout", "b5tsVR", "big5annual",
"big5meanannrich", "big5meanrichplot"))
rm(list = c("avg_biomass", "b5meantsVR", "b5siteout", "b5tsVR", "big5annual",
"big5meanannrich", "big5meanrichplot", "big5rich", "BP_dominance",
"dominance", "dompopstab", "domsp_agg_stab", "klee_annual", "klee_long",
"meanannrich", "meandompopstab", "meanplot_BPdom", "meanpopstab", "meanrichplot",
"meantsVR"))
View(res)
rm(list = c("avg_biomass", "b5meantsVR", "b5siteout", "b5tsVR", "big5annual",
"big5meanannrich", "big5meanrichplot", "big5rich", "BP_dominance",
"dominance", "dompopstab", "domsp_agg_stab", "klee_annual", "klee_long",
"meanannrich", "meandompopstab", "meanplot_BPdom", "meanpopstab", "meanrichplot",
"meantsVR", "nondom", "nondommeanannrich", "nondommeanrichplot"))
rm(list = c("avg_biomass", "b5meantsVR", "b5siteout", "b5tsVR", "big5annual",
"big5meanannrich", "big5meanrichplot", "big5rich", "BP_dominance",
"dominance", "dompopstab", "domsp_agg_stab", "klee_annual", "klee_long",
"meanannrich", "meandompopstab", "meanplot_BPdom", "meanpopstab", "meanrichplot",
"meantsVR", "nondom", "nondommeanannrich", "nondommeanrichplot", "nondomrich",
"pinhits", "plot", "plot2", "res", "res0", "resLong", "resShort",
"rich", "siteout", "stability", "VR_plots", "tsVR"))
source("current_scripts/full_timeseries_calcs.R")
## load packages
library(tidyverse)
library(lubridate)
source("precipitation_data_cleaning.R") ## read in data
source("current_scripts/precipitation_data_cleaning.R") ## read in data
## Classify Drought Years
## from total precipitation in the 12 months preceding sampling
ppt98_20$Monthnum <- as.character(ppt98_20$Monthnum)
View(ppt98_20)
## make sure the ppt data is in chronological order
ppt_forcalc <- ppt98_20 %>%
arrange(Date_final) %>%
filter(Date_final > "1998-06-15")  %>% ## filter out this June date so it's not included as a sampling period because this will mess with the for-loop.
mutate(Monthnum = ifelse(Monthnum == "10", Monthnum,
ifelse(Monthnum == "11", Monthnum,
ifelse(Monthnum == "12", Monthnum,
paste(0, Monthnum, sep = ""))))) %>% ## This line just adds a '0' before single digit month numbers to get it in a format that will work with the line below
mutate(Date_numeric = paste(year(Date_final), Monthnum, day(Date_final), sep = "")) #create column that can be coerced into numeric form as lubridate date format does not seem to work well in for-loops.
ppt_forcalc$Date_numeric <- as.numeric(ppt_forcalc$Date_numeric) ## make date numeric
june <- ppt_forcalc %>%
filter(Month %like% "un") %>% ## selecting June, but some are written June or Jun and the capitalization is not consistent
select(Date_numeric) %>%
arrange(Date_numeric)
sample_dates <- length(june$Date_numeric) ## calculate # of sample dates
## create dataframe of all July months - in order to bound the calculation period. Starts in 1998
july <- ppt_forcalc %>%
filter(Month %like% "ul") %>% ## select July
select(Date_numeric) %>%
arrange(Date_numeric)
## create empty data frame to contain the output
preceding12 <- data.frame(preceding12ppt = NA, sample_date = NA)
for (i in 1:sample_dates){
## select correct 12 month period and sum ppt
tempppt <- ppt_forcalc %>%
filter(Date_numeric <= june[i,]) %>% ## filter out obs after sampling date
filter(Date_numeric >= july[i,]) ## filter out obs before the previous sampling date -> leaves you with 12 months (11 preceding sample date and 1 including sample date)
meanppt <- tempppt %>%
summarise(preceding12ppt = sum(Average)) %>% ## sum the precipitation over these 12 months
mutate(sample_date = june[i,])
preceding12 <- rbind(preceding12, meanppt)
}
View(preceding12)
preceding12 <- preceding12[-1,] ## remove the row of NAs
View(ppt_forcalc)
## since this was collected in Sept, I need to sample from Sep98 - Aug99
y99 <- ppt_forcalc %>%
filter(Date_numeric <= 19980915, Date_numeric >= 19990815)
## since this was collected in Sept, I need to sample from Sep98 - Aug99
y99 <- ppt_forcalc %>%
filter(Date_numeric <= 19980915, Date_numeric >= 19990815) %>%
summarise(preceding12ppt = sum(Average)) %>%
mutate(sample_date = 19990915)
View(y99)
y99 <- ppt_forcalc %>%
filter(Date_numeric <= 19980915, Date_numeric >= 19990815)
y99 <- ppt_forcalc %>%
filter(Date_numeric <= 19980915)
y99 <- ppt_forcalc %>%
filter(Date_numeric <= 19980915) %>%
filter(Date_numeric >= 19990815)
y99 <- ppt_forcalc %>%
filter(Date_numeric >= 19980915)
y99 <- ppt_forcalc %>%
filter(Date_numeric >= 19980915) %>%
filter(Date_numeric <= 19990815)
## since this was collected in Sept, I need to sample from Sep98 - Aug99
y99 <- ppt_forcalc %>%
filter(Date_numeric >= 19980915) %>%
filter(Date_numeric <= 19990815) %>%
summarise(preceding12ppt = sum(Average)) %>%
mutate(sample_date = 19990915)
## since this was collected in Feb, I need to sample from Feb02 - Jan03
y03 <- ppt_forcalc %>%
filter(Date_numeric <= 20030115, Date_numeric >= 20020215) %>%
summarise(preceding12ppt = sum(Average)) %>%
mutate(sample_date = 20020215)
View(y03)
prec12 <- preceding12 %>%
filter(Date_numeric != c("19990615", "20030615"))
prec12 <- preceding12 %>%
filter(sample_date != c("19990615", "20030615"))
View(prec12)
prec12 <- preceding12 %>%
filter(sample_date != "19990615", sample_date != "20030615"))
prec12 <- preceding12 %>%
filter(sample_date != "19990615", sample_date != "20030615")
prec12 <- preceding12 %>%
filter(sample_date != 19990615, sample_date != 20030615)
x <- rbind(prec12, y99)
prec12_corrected <- rbind(x, y03)
View(prec12_corrected)
## since this was collected in Feb, I need to sample from Feb02 - Jan03
y03 <- ppt_forcalc %>%
filter(Date_numeric <= 20030115, Date_numeric >= 20020215) %>%
summarise(preceding12ppt = sum(Average)) %>%
mutate(sample_date = 20030215)
## remove the incorrect 03 and 99 dates from this dataframe
prec12 <- preceding12 %>%
filter(sample_date != 19990615, sample_date != 20030615)
x <- rbind(prec12, y99)
prec12_corrected <- rbind(x, y03)
## classify drought events
drought_record <- prec12_corrected %>%
mutate(drought = ifelse(prec12_corrected <= quantile(prec12_corrected, probs = 0.25, na.rm = T), 1, 0))
View(drought_record)
rm(x)
rm(list = c("x", "prec12"))
## Classify Drought Events ##
drought_record <- prec12_corrected %>%
mutate(drought = ifelse(preceding12ppt <= quantile(prec12_corrected, probs = 0.25, na.rm = T), 1, 0))
## calculate the percentiles from 0-100 of the precipitation record
quant <- data.frame(percentile = c(0:100), ppt_value = quantile(drought_record$preceding12ppt, seq(0, 1, .01))) %>%
arrange(percentile)
View(quant)
## define a function to quantify the percentile that any given precipitation amount falls into from 1-100
ppt_per_func <- function (precip, q, ...) {
for (i in 1:length(q$percentile)) {
## check if the ppt value is less than or equal to each percentile value
if (precip <= q$ppt_value[i]) {
## the first percentile is technically called the 0th percentile by the quantile function,
## so when a ppt value falls in the first quantile, we need to assign the index (1)
## as the percentile rather than keeping the percentile from the quantile function
if (i == 1) {
percentile <- i
## for all other percentiles, i-1 should give the correct percentile
}else{
percentile <- i - 1
}
break()
}
}
return(percentile)
}
## test the function
ppt_per_func(precip = 490.800, q = quant)
## test the function
ppt_per_func(precip = 490.700, q = quant)
## test the function
ppt_per_func(precip = 490.799, q = quant)
ppt_per_func(precip = 211.300, q = quant) ## calls this 1st %tile rather than 0th - good!
## Use the new ppt percentile function for every ppt value in the ppt record ##
nyears <- length(drought_record$preceding12ppt) ## calculate # of years to iterate over
## make an empty dataframe to contain the output
dperc_record <- data.frame(preceding12ppt = NA, sample_date = NA, drought = NA, percentile = NA)
## iterate over every year
for (j in 1:nyears) {
## select the particular ppt record
ppt <- drought_record$preceding12ppt[j]
## filter out the correct row in drought_record
dtemp <- drought_record %>%
filter(preceding12ppt %in% ppt)
## use the function defined above to calculate the percentile
percentile <- ppt_per_func(precip = ppt, q = quant)
## append this to the temp data frame in new column
dtemp$percentile <- percentile
## append temp dataframe to output dataframe
dperc_record <- rbind(dperc_record, dtemp)
}
View(dperc_record)
dperc_record <- dperc_record[-1,] ## remove first row of NA values
## test the function
ppt_per_func(precip = 530, q = quant)
## define a function to quantify the percentile that any given precipitation amount falls into from 1-100
ppt_per_func <- function (precip, q, ...) {
for (i in 1:length(q$percentile)) {
## check if the ppt value is less than or equal to each percentile value
if (precip <= q$ppt_value[i]) {
## the first percentile is technically called the 0th percentile by the quantile function,
## so when a ppt value falls in the first quantile, we need to assign the index (1)
## as the percentile rather than keeping the percentile from the quantile function
if (i == 1) {
percentile <- i
## for all other percentiles, i-1 should give the correct percentile
}else{
percentile <- i - 1
}
break()
}
}
return(percentile)
}
## Use the new ppt percentile function for every ppt value in the ppt record ##
nyears <- length(drought_record$preceding12ppt) ## calculate # of years to iterate over
## make an empty dataframe to contain the output
dperc_record <- data.frame(preceding12ppt = NA, sample_date = NA, drought = NA, percentile = NA)
## iterate over every year
for (j in 1:nyears) {
## select the particular ppt record
ppt <- drought_record$preceding12ppt[j]
## filter out the correct row in drought_record
dtemp <- drought_record %>%
filter(preceding12ppt %in% ppt)
## use the function defined above to calculate the percentile
percentile <- ppt_per_func(precip = ppt, q = quant)
## append this to the temp data frame in new column
dtemp$percentile <- percentile
## append temp dataframe to output dataframe
dperc_record <- rbind(dperc_record, dtemp)
}
dperc_record <- dperc_record[-1,] ## remove first row of NA values
## Classify Drought Events ##
drought_record <- prec12_corrected %>%
mutate(drought = ifelse(prec12_corrected <= quantile(prec12_corrected, probs = 0.25, na.rm = T), 1, 0))
quantile(prec12_corrected, probs = 0.25, na.rm = T)
?quantile
quantile(prec12_corrected, probs = 0.75, na.rm = T)
quantile(prec12_corrected$preceding12ppt, probs = 0.75, na.rm = T)
quantile(prec12_corrected$preceding12ppt, probs = 0.25, na.rm = T)
## Classify Drought Events ##
drought_record <- prec12_corrected %>%
mutate(drought = ifelse(preceding12ppt <= quantile(prec12_corrected$preceding12ppt, probs = 0.25, na.rm = T), 1, 0))
## calculate the percentiles from 0-100 of the precipitation record
quant <- data.frame(percentile = c(0:100), ppt_value = quantile(drought_record$preceding12ppt, seq(0, 1, .01))) %>%
arrange(percentile)
## define a function to quantify the percentile that any given precipitation amount falls into from 1-100
ppt_per_func <- function (precip, q, ...) {
for (i in 1:length(q$percentile)) {
## check if the ppt value is less than or equal to each percentile value
if (precip <= q$ppt_value[i]) {
## the first percentile is technically called the 0th percentile by the quantile function,
## so when a ppt value falls in the first quantile, we need to assign the index (1)
## as the percentile rather than keeping the percentile from the quantile function
if (i == 1) {
percentile <- i
## for all other percentiles, i-1 should give the correct percentile
}else{
percentile <- i - 1
}
break()
}
}
return(percentile)
}
## test the function
ppt_per_func(precip = 530, q = quant)
ppt_per_func(precip = 211.300, q = quant) ## calls this 1st %tile rather than 0th - good!
## Use the new ppt percentile function for every ppt value in the ppt record ##
nyears <- length(drought_record$preceding12ppt) ## calculate # of years to iterate over
## make an empty dataframe to contain the output
dperc_record <- data.frame(preceding12ppt = NA, sample_date = NA, drought = NA, percentile = NA)
## iterate over every year
for (j in 1:nyears) {
## select the particular ppt record
ppt <- drought_record$preceding12ppt[j]
## filter out the correct row in drought_record
dtemp <- drought_record %>%
filter(preceding12ppt %in% ppt)
## use the function defined above to calculate the percentile
percentile <- ppt_per_func(precip = ppt, q = quant)
## append this to the temp data frame in new column
dtemp$percentile <- percentile
## append temp dataframe to output dataframe
dperc_record <- rbind(dperc_record, dtemp)
}
dperc_record <- dperc_record[-1,] ## remove first row of NA values
# CALCULATE DROUGHT SEVERITY #
## drought severity = 1-((precip_percentile - 1)/25)
d_severity <- dperc_record %>%
mutate(severity = ifelse(drought == "1", (1 - ((percentile - 1)/25)), 0)) ## divide by 25 as that's the # of divisions in quartile 1
# CALCULATE DROUGHT SEVERITY #
## drought severity = 1-((precip_percentile - 1)/25)
d_severity <- dperc_record %>%
mutate(severity = ifelse(drought == "1", (1 - ((percentile - 1)/25)), 0)) ## divide by 25 as that's the # of divisions in quartile 1
View(d_severity)
# CALCULATE TOTAL DROUGHT SCORE IN EVERY WINDOW #
## first, identify years following droughts to eventually account for lag effects
d_sever_prev <- d_severity %>%
mutate(drought_prev = ifelse(drought == 1, 0,
ifelse(lag(drought, default = 0) == 1, 1, 0)))
View(dperc_record)
View(quant)
i <- 36
q <- quant
source("current_scripts/movingwindow_calcs.R")
source("current_scripts/movingwindow_calcs.R")
setwd("~/Repositories/klee-stability")
library(tidyverse)
source("current_scripts/movingwindow_calcs.R")
source("/current_scripts/movingwindow_calcs.R")
source("current_scripts/movingwindow_calcs.R")
source("current_scripts/movingwindow_calcs.R")
source("current_scripts/movingwindow_calcs.R")
source("current_scripts/drought_score_calcs")
source("current_scripts/drought_score_calcs.R")
rm(list = c("d_sever_prev", "d_severity", "dperc_record", "dtemp", "june", "july", "meanppt", "ppt_forcalc",
"ppt98_20", "pptmean", "pptrange", "preceding12", "quant", "tempppt", "prec12_corrected", "y03", "y99"))
source("current_scripts/movingwindow_calcs.R")
source("current_scripts/drought_score_calcs.R")
View(dscore10)
View(mw10all)
## join 10 year moving window data with drought score
dmw10 <- left_join(mw10all, dscore10, by = "timestep")
dmw5 <- left_join(mw5all, dscore5, by = "timestep")
source("current_scripts/finalprep_postcalcs.R")
model <- psem(
lmer(stability~Dscore+TREATMENT + classicVR + mean_popst + (1|BLOCK) + (1|Unique_ID), data=stabmechmw10),
lmer(classicVR~Dscore+TREATMENT + richness + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10),
lmer(mean_popst~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10),
lmer(richness~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10)
)
library(piecewiseSEM)
library(multcompView)
model <- psem(
lmer(stability~Dscore+TREATMENT + classicVR + mean_popst + (1|BLOCK) + (1|Unique_ID), data=stabmechmw10),
lmer(classicVR~Dscore+TREATMENT + richness + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10),
lmer(mean_popst~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10),
lmer(richness~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10)
)
library(lme4)
model <- psem(
lmer(stability~Dscore+TREATMENT + classicVR + mean_popst + (1|BLOCK) + (1|Unique_ID), data=stabmechmw10),
lmer(classicVR~Dscore+TREATMENT + richness + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10),
lmer(mean_popst~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10),
lmer(richness~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = stabmechmw10)
)
model <- psem(
lmer(stability~Dscore+TREATMENT + classicVR + mean_popst + (1|BLOCK) + (1|Unique_ID), data=dmw10),
lmer(classicVR~Dscore+TREATMENT + richness + (1|BLOCK) + (1|Unique_ID), data = dmw10),
lmer(mean_popst~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = dmw10),
lmer(richness~Dscore+TREATMENT + (1|BLOCK) + (1|Unique_ID), data = dmw10)
)
summary(model)
model2 <- psem(
lmer(stability~Dscore+cows+wildlife+mega + classicVR + mean_popst + (1|BLOCK) + (1|Unique_ID), data=dmw10),
lmer(classicVR~Dscore+cows+wildlife+mega + richness + (1|BLOCK) + (1|Unique_ID), data = dmw10),
lmer(mean_popst~Dscore+cows+wildlife+mega + (1|BLOCK) + (1|Unique_ID), data = dmw10),
lmer(richness~Dscore+cows+wildlife+mega + (1|BLOCK) + (1|Unique_ID), data = dmw10)
)
summary(model2)
sem.fit()
?sem.fit()
??sem.fit()
